# -*- coding: utf-8 -*-
"""Chocolate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10QNN28WwB9AIzjbkhwygy5OWhHtjR8wg
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import io
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import holoviews as hv
from holoviews import opts
import warnings

CH = pd.read_csv("Chocolate Sales.csv")

CH.head(5)

CH.tail(5)

CH.shape

CH.describe()

CH.info()

CH.value_counts()

CH.isnull().sum()

"""-- EDA --

"""

CH.corr

# Group by 'Sales Person' and sum the amounts.
sales_by_person = CH.groupby('Sales Person')['Amount'].sum().reset_index()

# Identify the Best Seller.
best_seller = sales_by_person.loc[sales_by_person['Amount'].idxmax(), 'Sales Person']

# Highlight the Best Seller.
colors = ['red' if person == best_seller else 'skyblue' for person in sales_by_person['Sales Person']]

# Plot the results.
plt.figure(figsize=(12, 6))
sns.barplot(data=sales_by_person, x='Sales Person', y='Amount', palette=colors)
plt.xlabel("Sales Person")
plt.ylabel("Total Sales ($)")
plt.title("Sales by Person")
plt.tight_layout()
plt.xticks(rotation=45, fontsize=8);
plt.show()

plt.figure(figsize=(10, 6))

sns.countplot(data=CH,x='Country')

plt.figure(figsize=(12,6))
sns.countplot(data=CH,x=CH['Product'])
plt.xticks(rotation=45, ha='right')
plt.show()

plt.figure(figsize=(12,6))
plt.title('Product vs Amount')
sns.barplot(data=CH,x='Product',y="Amount")
plt.xticks(rotation=45, ha='right')
plt.show()

plt.figure(figsize=(12, 6))
sns.lineplot(data=CH, x='Date', y='Amount')
plt.xlabel("Date")
plt.ylabel("Amount")
plt.title("Sales Amount Over Time")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# prompt: Create a comapering plot between products and contry

# Assuming 'CH' DataFrame is already loaded as in the provided code.

plt.figure(figsize=(12, 6))
sns.barplot(data=CH, x='Country', y='Amount', hue='Product')
plt.xlabel("Country")
plt.ylabel("Total Amount")
plt.title("Total Amount by Country and Product")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

fig = px.bar(CH, x='Country', y='Amount', color='Product',
             title='Total Amount by Country and Product',
             labels={'Amount': 'Total Amount', 'Country': 'Country', 'Product': 'Product'},
             hover_data=['Date', 'Sales Person']) # Added hover data for more information
fig.update_layout(xaxis={'categoryorder':'total descending'}) # Order countries by total sales
fig.show()

numeric_columns = ['Amount', 'Boxes Shipped']

# Distribution with Histograms.
for col in numeric_columns:
    plt.figure(figsize=(12, 6))
    sns.histplot(CH[col], kde=True)
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.title(f"Distribution of {col}")
    plt.tight_layout()
    plt.show()

# Distribution with Boxen and Violin Plots.
for col in numeric_columns:
    fig, ax = plt.subplots(1, 2, figsize=(12, 6))
    sns.boxenplot(y=CH[col], ax=ax[0])
    ax[0].set_title(f"Boxen Plot of {col}")
    sns.violinplot(y=CH[col], ax=ax[1])
    ax[1].set_title(f"Violin Plot of {col}")
    plt.tight_layout()
    plt.show()

# Convert 'Date' Column to datetime format
CH['Date'] = pd.to_datetime(CH['Date'], format='%d-%b-%y')

# # Group the data by month and sum the sales amounts
sales_time = CH.groupby(pd.Grouper(key='Date', freq='M'))['Amount'].sum().reset_index()

# Plot the sales trend over time
plt.figure(figsize=(12, 6))
sns.lineplot(data=sales_time, x='Date', y='Amount', marker='o')
plt.xlabel("Date")
plt.ylabel("Total Sales ($)")
plt.title("Sales Trend Over Time")
plt.tight_layout()
plt.show()

hv.extension('bokeh')

unique_labels = list(set(CH['Country']).union(set(CH['Sales Person'])))
label_map = {label: i for i, label in enumerate(unique_labels)}

links = [(label_map[row['Country']], label_map[row['Sales Person']], row['Amount']) for _, row in CH.iterrows()]

nodes = hv.Dataset(pd.DataFrame({'index': list(label_map.values()), 'label': list(label_map.keys())}), 'index')

chord = hv.Chord((links, nodes)).opts(
    opts.Chord(labels='label', cmap='Category20', edge_cmap='viridis', edge_color='Amount', node_color='index', node_size=20, width=800, height=800)
)

chord

"""-- Modeling Building --
-- Modeling Evaluation --

"""

# Pre processing
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import time
# Model Libs
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# Hyper-parameter Libs
from sklearn.model_selection import cross_val_score

"""-- Data Splitting --"""

# Define features (X) and target (y)
X = CH.drop(['Amount', 'Date',], axis=1)
y = CH['Amount']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print the shapes of the resulting datasets to verify the split
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""-- Model Training --"""

dt_model = DecisionTreeRegressor(random_state=42)
rf_model = RandomForestRegressor(random_state=42)
xgb_model = XGBRegressor(random_state=42)
LR_model = LinearRegression()
lgb_model = LGBMRegressor(random_state=42)

# Define features (X) and target (y)
X = CH.drop(['Amount', 'Date'], axis=1)
# Remove currency symbols and commas from the 'Amount' column and convert to numeric
y = CH['Amount'].str.replace('$', '').str.replace(',', '').astype(float)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print the shapes of the resulting datasets to verify the split
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)



"""-> Decision Tree"""

# Train the Decision Tree model
dt_model.fit(X_train, y_train)

# Make predictions on the test set
dt_predictions = dt_model.predict(X_test)

# Evaluate the model
dt_mse = mean_squared_error(y_test, dt_predictions)
dt_mae = mean_absolute_error(y_test, dt_predictions)
dt_r2 = r2_score(y_test, dt_predictions)

print("Decision Tree Regression Results:")
print(f"Mean Squared Error (MSE): {dt_mse}")
print(f"Mean Absolute Error (MAE): {dt_mae}")
print(f"R-squared (R2): {dt_r2}")

"""-> Random Forest Model

"""

# Train the Random Forest model
rf_model.fit(X_train, y_train)

# Make predictions on the test set
rf_predictions = rf_model.predict(X_test)

# Evaluate the model
rf_mse = mean_squared_error(y_test, rf_predictions)
rf_mae = mean_absolute_error(y_test, rf_predictions)
rf_r2 = r2_score(y_test, rf_predictions)

print("Random Forest Regression Results:")
print(f"Mean Squared Error (MSE): {rf_mse}")
print(f"Mean Absolute Error (MAE): {rf_mae}")
print(f"R-squared (R2): {rf_r2}")

"""-> XGBoost"""

# Train the XGBoost
xgb_model.fit(X_train, y_train)

# Make Prediction on set
xgb_prediction = xgb_model.predict(X_test)

# Evulate the model
xgb_mse = mean_squared_error(y_test, xgb_prediction)
xgb_mae = mean_absolute_error(y_test, xgb_prediction)
xgb_r2 = r2_score(y_test, xgb_prediction)

print("XGBoost Regression Results:")
print(f"Mean Squared Error (MSE): {xgb_mse}")
print(f"Mean Absolute Error (MAE): {xgb_mae}")
print(f"R-squared (R2): {xgb_r2}")

"""-> Linear regression

"""

# Train the Linear regression
LR_model.fit(X_train, y_train)

# Make Prediction on set
LR_prediction = LR_model.predict(X_test)

# Evulate the model
LR_mse = mean_squared_error(y_test, LR_prediction)
LR_mae = mean_absolute_error(y_test, LR_prediction)
LR_r2 = r2_score(y_test, LR_prediction)

print("Linear regression Results:")
print(f"Mean Squared Error (MSE): {LR_mse}")
print(f"Mean Absolute Error (MAE): {LR_mae}")
print(f"R-squared (R2): {LR_r2}")

"""-> LightGB model"""

# Train the LightGB model
lgb_model.fit(X_train, y_train)

# Make Prediction on set
lgb_prediction = lgb_model.predict(X_test)

# Evulate the model
lgb_mse = mean_squared_error(y_test, lgb_prediction)
lgb_mae = mean_absolute_error(y_test, lgb_prediction)
lgb_r2 = r2_score(y_test, lgb_prediction)

print("LightGB model Results:")
print(f"Mean Squared Error (MSE): {lgb_mse}")
print(f"Mean Absolute Error (MAE): {lgb_mae}")
print(f"R-squared (R2): {lgb_r2}")

model_names = ['Decision Tree', 'Random Forest', 'XGBoost', 'Linear Regression', 'LightGBM']
mse_scores = [dt_mse, rf_mse, xgb_mse, LR_mse, lgb_mse]
mae_scores = [dt_mae, rf_mae, xgb_mae, LR_mae, lgb_mae]
r2_scores = [dt_r2, rf_r2, xgb_r2, LR_r2, lgb_r2]

# Create the plot
x = range(len(model_names))
width = 0.2

fig, ax = plt.subplots(figsize=(12, 6))
rects1 = ax.bar(x, mse_scores, width, label='MSE')
rects2 = ax.bar([i + width for i in x], mae_scores, width, label='MAE')
rects3 = ax.bar([i + 2 * width for i in x], r2_scores, width, label='R-squared')

# Add labels, title, and legend
ax.set_ylabel('Scores')
ax.set_title('Model Comparison')
ax.set_xticks([i + width for i in x])
ax.set_xticklabels(model_names)
ax.legend()

plt.show()



